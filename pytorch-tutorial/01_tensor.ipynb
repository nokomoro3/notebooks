{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l92fnMTyG2qf"
   },
   "source": [
    "### __Doc__\n",
    "- https://jovian.ai/aakashns/01-pytorch-basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l92fnMTyG2qf"
   },
   "source": [
    "### __Setup__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1632324690044,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "DjzGBa5Cx5SJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ_y568QH9ge"
   },
   "source": [
    "### __tensorとndarray__\n",
    "- せっかくなので、似ているnumpy配列とtensorを比較してみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1632325014553,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "r7LkwbB9HSiR",
    "outputId": "8f3fa3d5-8ac1-4780-bf9d-28f6dd63c144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(4)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = torch.tensor(4)\n",
    "display(t1)\n",
    "\n",
    "arr1 = np.asarray(4)\n",
    "display(arr1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWKwfFWVJ0Ag"
   },
   "source": [
    "- 全要素が整数型の場合、勝手に整数型になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1632325017396,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "0gLhtjBPHdrd",
    "outputId": "91ca8062-3892-4c37-f307-dded1c5ee33f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.int64\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'numpy.ndarray'>, dtype: int64\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"type: {type(t1)}, dtype: {t1.dtype}\")\n",
    "display(f\"type: {type(arr1)}, dtype: {arr1.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1K_SfO0LF_f"
   },
   "source": [
    "- 浮動小数の場合は、浮動小数になるが、torchとnumpyでデフォルトのビット数が違う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1632325086284,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "LetcerHDJ-Nu",
    "outputId": "3bae3799-a48e-495e-b8cc-9d4772ebf3a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(4.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'numpy.ndarray'>, dtype: float64\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t1 = torch.tensor(4.)\n",
    "display(t1)\n",
    "\n",
    "arr1 = np.asarray(4.)\n",
    "display(arr1)\n",
    "\n",
    "display(f\"type: {type(t1)}, dtype: {t1.dtype}\")\n",
    "display(f\"type: {type(arr1)}, dtype: {arr1.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQscpjQiLybO"
   },
   "source": [
    "- 明示的に指定したいときはこのようにする。\n",
    "- デフォルトの場合は、dtypeが出力されないのは、少し不親切ではあると思う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1632325323849,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "4FRmyH3JHjmJ",
    "outputId": "3f341a62-120b-44ca-d9a7-e2eb18620509"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4.], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t2 = torch.tensor([1,2,3,4])\n",
    "display(t2)\n",
    "arr2 = np.asarray([1,2,3,4])\n",
    "display(arr2)\n",
    "\n",
    "t2 = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
    "display(t2)\n",
    "arr2 = np.asarray([1,2,3,4], dtype=np.float32)\n",
    "display(arr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wN8bonViL8kF"
   },
   "source": [
    "- 多次元配列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1632325935123,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "CmE4K4ldMBPg",
    "outputId": "4c417cbc-89f9-40f9-ef9d-7c1882f30253"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([2, 4])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4.],\n",
       "        [1., 2., 3., 4.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'numpy.ndarray'>, dtype: float32, shape: (2, 4)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[1., 2., 3., 4.],\n",
       "       [1., 2., 3., 4.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t3 = torch.tensor([[1,2,3,4],[1,2,3,4]], dtype=torch.float32)\n",
    "display(f\"type: {type(t3)}, dtype: {t3.dtype}, shape: {t3.shape}\")\n",
    "display(t3)\n",
    "\n",
    "arr3 = np.asarray([[1,2,3,4],[1,2,3,4]], dtype=np.float32)\n",
    "display(f\"type: {type(arr3)}, dtype: {arr3.dtype}, shape: {arr3.shape}\")\n",
    "display(arr3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __dtype変換__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 途中でdtypeを変えたいことはよくある。\n",
    "- torchでは、toを使い、numpyではastypeを使う。(astypeの方が明示的でわかりやすいなぁ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float64, shape: torch.Size([2, 4])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'numpy.ndarray'>, dtype: float64, shape: (2, 4)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t3 = t3.to(torch.float64)\n",
    "display(f\"type: {type(t3)}, dtype: {t3.dtype}, shape: {t3.shape}\")\n",
    "\n",
    "arr3 = arr3.astype(np.float64)\n",
    "display(f\"type: {type(arr3)}, dtype: {arr3.dtype}, shape: {arr3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __tensorとndarrayの相互変換__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __tensor to ndarray__\n",
    "- dtypeは維持される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float64, shape: torch.Size([2, 4])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'numpy.ndarray'>, dtype: float64, shape: (2, 4)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t3_to_arr = t3.numpy()\n",
    "\n",
    "display(f\"type: {type(t3)}, dtype: {t3.dtype}, shape: {t3.shape}\")\n",
    "display(f\"type: {type(t3_to_arr)}, dtype: {t3_to_arr.dtype}, shape: {t3_to_arr.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __ndarray to tensor__\n",
    "- こちらもdtypeは維持されそう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'numpy.ndarray'>, dtype: float64, shape: (2, 4)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float64, shape: torch.Size([2, 4])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "arr3_to_tensor = torch.from_numpy(arr3)\n",
    "\n",
    "display(f\"type: {type(arr3)}, dtype: {arr3.dtype}, shape: {arr3.shape}\")\n",
    "display(f\"type: {type(arr3_to_tensor)}, dtype: {arr3_to_tensor.dtype}, shape: {arr3_to_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __配列初期化__\n",
    "実際には、数値でテンソルを初期化することは少ない。<br>\n",
    "よく使うのは、zeros, ones, randomあたりか。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbI4ZprRNeFd"
   },
   "source": [
    "#### __zeros__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1632326040074,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "pNcJBn5_NjW2",
    "outputId": "596c5650-a0ab-4c31-a883-8dff04e8b2cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([3, 3, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t4 = torch.zeros(3,3,3) # numpyならnp.zeros\n",
    "display(f\"type: {type(t4)}, dtype: {t4.dtype}, shape: {t4.shape}\")\n",
    "display(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __ones__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1632326078275,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "Yf6PQ4fiNu56",
    "outputId": "b46e7676-3b91-49b4-d506-e4c33ef66ff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([3, 3, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]],\n",
       "\n",
       "        [[1., 1., 1.],\n",
       "         [1., 1., 1.],\n",
       "         [1., 1., 1.]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t5 = torch.ones(3,3,3) # numpyならnp.ones\n",
    "display(f\"type: {type(t5)}, dtype: {t5.dtype}, shape: {t5.shape}\")\n",
    "display(t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __乱数__\n",
    "- 乱数初期化は、色々な分布があるので注意。\n",
    "- 標準正規分布は以下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1632326146290,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "wsYvmQRpN9s7",
    "outputId": "31767bd6-65b9-4728-b3ce-5180fe7805ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([3, 3, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9218,  0.2755, -0.5224],\n",
       "         [-0.4004,  1.3699,  0.8453],\n",
       "         [-0.0747, -1.1937, -0.3216]],\n",
       "\n",
       "        [[ 0.3456,  1.2419,  2.2675],\n",
       "         [ 0.4432,  0.6822, -0.7272],\n",
       "         [-0.1133, -1.8460,  0.8344]],\n",
       "\n",
       "        [[-0.5757, -0.3951,  1.3431],\n",
       "         [ 1.1039,  1.4984,  0.6808],\n",
       "         [ 0.0522,  1.2710, -1.5283]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t6 = torch.randn(3,3,3) # numpyならnp.random.randnかな？\n",
    "display(f\"type: {type(t6)}, dtype: {t6.dtype}, shape: {t6.shape}\")\n",
    "display(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 一様分布は以下。範囲は、[0,1)なので 0 <= x < 1です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([3, 3, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7256, 0.1754, 0.2362],\n",
       "         [0.7754, 0.1954, 0.3376],\n",
       "         [0.8809, 0.1242, 0.2402]],\n",
       "\n",
       "        [[0.2988, 0.0776, 0.0455],\n",
       "         [0.6565, 0.4469, 0.8965],\n",
       "         [0.8439, 0.8876, 0.4639]],\n",
       "\n",
       "        [[0.7040, 0.1309, 0.2277],\n",
       "         [0.1789, 0.3798, 0.6330],\n",
       "         [0.7794, 0.9599, 0.8111]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t6 = torch.rand(3,3,3) # numpyならnp.random.randかな？\n",
    "display(f\"type: {type(t6)}, dtype: {t6.dtype}, shape: {t6.shape}\")\n",
    "display(t6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __full(同じ値で埋める)__\n",
    "- チュートリアルにはあるものの、zerosを使えば事足りるので、あまり使わない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.int64, shape: torch.Size([3, 3, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[10, 10, 10],\n",
       "         [10, 10, 10],\n",
       "         [10, 10, 10]],\n",
       "\n",
       "        [[10, 10, 10],\n",
       "         [10, 10, 10],\n",
       "         [10, 10, 10]],\n",
       "\n",
       "        [[10, 10, 10],\n",
       "         [10, 10, 10],\n",
       "         [10, 10, 10]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t7 = torch.full((3,3,3), 10)\n",
    "display(f\"type: {type(t7)}, dtype: {t7.dtype}, shape: {t7.shape}\")\n",
    "display(t7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __配列結合__\n",
    "- これは何気に頻繁に登場する。\n",
    "- numpyでも役立つので、Python使いなら習熟しなければならない。\n",
    "- 結合は具体例がある方がいいので、以下の構成の画像のデータを想定して説明する。\n",
    "  - img ... バッチサイズ x 横画素数 x 縦画素数 x チャネル数(RGB=3)\n",
    "  - 具体例としては、10 x 128 x 128 x 3など。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __結合__\n",
    "- torchの場合は、torch.cat\n",
    "- numpyの場合は、np.concatenate\n",
    "- pandasの場合は、pd.concat（テーブルデータなので2次元以上はないけど）\n",
    "\n",
    "と方言があるので注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = torch.zeros((1000,128,128,3), dtype=torch.float32)\n",
    "img2 = torch.zeros((1000,128,128,3), dtype=torch.float32)\n",
    "display(f\"type: {type(img1)}, dtype: {img1.dtype}, shape: {img1.shape}\")\n",
    "display(f\"type: {type(img2)}, dtype: {img2.dtype}, shape: {img2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- axis=0は、一番左(メモリ的に遠い位置)で結合される。\n",
    "  - これは、img1, img2のそれぞれのメモリ配置を変更せずにくっつけることに等しい。\n",
    "  - 軸を指定しない場合、axis=0と同じ動きとなるようだ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([2000, 128, 128, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.3 ms, sys: 236 ms, total: 270 ms\n",
      "Wall time: 57.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "img_cat1 = torch.cat((img1, img2))\n",
    "display(f\"type: {type(img_cat1)}, dtype: {img_cat1.dtype}, shape: {img_cat1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- axis=3とすると、一番右(メモリ的に近い要素)で結合される。\n",
    "  - img1, img2の配置が変わるため、結合に時間がかかるはず。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 6])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 301 ms, sys: 180 ms, total: 481 ms\n",
      "Wall time: 94.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "img_cat2 = torch.cat((img1, img2), axis=3)\n",
    "display(f\"type: {type(img_cat2)}, dtype: {img_cat2.dtype}, shape: {img_cat2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4次元配列の場合、axis=3はaxis=-1と同じ処理となる。\n",
    "  - 場合によっては、axis=3とするのは、拡張性がない場合もある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 6])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_cat2 = torch.cat((img1, img2), axis=-1)\n",
    "display(f\"type: {type(img_cat2)}, dtype: {img_cat2.dtype}, shape: {img_cat2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __異なる次元を結合__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4次元配列と3次元配列の結合は、そのままではできない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "torch.cat(): Tensors must have same number of dimensions: got 4 and 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_746/3039341598.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg_cat3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: torch.cat(): Tensors must have same number of dimensions: got 4 and 3"
     ]
    }
   ],
   "source": [
    "img1 = torch.zeros((1000,128,128,3), dtype=torch.float32)\n",
    "img3 = torch.zeros((1000,128,128), dtype=torch.float32)\n",
    "\n",
    "img_cat3 = torch.cat((img1, img3), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- こういった場合に、reshapeを使えば解決する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 1])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 4])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img3_reshaped = img3.reshape(img3.shape[0], img3.shape[1], img3.shape[2], 1)\n",
    "display(f\"type: {type(img3_reshaped)}, dtype: {img3_reshaped.dtype}, shape: {img3_reshaped.shape}\")\n",
    "\n",
    "img_cat3 = torch.cat((img1, img3_reshaped), axis=-1)\n",
    "display(f\"type: {type(img_cat3)}, dtype: {img_cat3.dtype}, shape: {img_cat3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ただ、要素数1の次元を増やすには、reshapeは記述が長くてめんどいので。\n",
    "- torch限定ではあるが、unsqueezeを使う方が記述は少なくて済む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 1])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 4])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = torch.zeros((1000,128,128,3), dtype=torch.float32)\n",
    "img4 = torch.zeros((1000,128,128), dtype=torch.float32)\n",
    "\n",
    "img4_reshaped = img4.unsqueeze(dim=-1) # 一番右の次元に要素数1の次元を追加\n",
    "display(f\"type: {type(img4_reshaped)}, dtype: {img4_reshaped.dtype}, shape: {img4_reshaped.shape}\")\n",
    "\n",
    "img_cat4 = torch.cat((img1, img4_reshaped), axis=-1)\n",
    "display(f\"type: {type(img_cat4)}, dtype: {img_cat4.dtype}, shape: {img_cat4.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- unsqueezeの引数、dimは元の次元数+1まで指定できるようになっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1, 1000, 128, 128])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 1, 128, 128])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 1, 128])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 1])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img5 = torch.zeros((1000,128,128), dtype=torch.float32)\n",
    "display(f\"type: {type(img5)}, dtype: {img5.dtype}, shape: {img5.shape}\")\n",
    "\n",
    "img5_reshaped1 = img5.unsqueeze(dim=0)\n",
    "display(f\"type: {type(img5_reshaped1)}, dtype: {img5_reshaped1.dtype}, shape: {img5_reshaped1.shape}\")\n",
    "\n",
    "img5_reshaped2 = img5.unsqueeze(dim=1)\n",
    "display(f\"type: {type(img5_reshaped2)}, dtype: {img5_reshaped2.dtype}, shape: {img5_reshaped2.shape}\")\n",
    "\n",
    "img5_reshaped3 = img5.unsqueeze(dim=2)\n",
    "display(f\"type: {type(img5_reshaped3)}, dtype: {img5_reshaped3.dtype}, shape: {img5_reshaped3.shape}\")\n",
    "\n",
    "img5_reshaped3 = img5.unsqueeze(dim=3) # dim=-1と同じ\n",
    "display(f\"type: {type(img5_reshaped3)}, dtype: {img5_reshaped3.dtype}, shape: {img5_reshaped3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __配列変形__\n",
    "- reshapeやunsqueezeが出てきたが、もう少し深堀する。\n",
    "\n",
    "#### __reshape__\n",
    "- まずはrehshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 16384, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = torch.randn((1000,128,128,3), dtype=torch.float32)\n",
    "display(f\"type: {type(img1)}, dtype: {img1.dtype}, shape: {img1.shape}\")\n",
    "\n",
    "img1_reshape1 = img1.reshape(1000,128*128,3)\n",
    "display(f\"type: {type(img1_reshape1)}, dtype: {img1_reshape1.dtype}, shape: {img1_reshape1.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reshapeの要素数は、１か所のみ-1を指定することができる。その場合は、良い感じのサイズにしてくれる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 16384, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1_reshape2 = img1.reshape(1000,-1,3)\n",
    "display(f\"type: {type(img1_reshape2)}, dtype: {img1_reshape2.dtype}, shape: {img1_reshape2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ちなみに、reshapeは、次元を入れ替えているわけではない。\n",
    "- あくまでメモリ上の並び順は同じである。以下テスト用の配列を再定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.int64, shape: torch.Size([6, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: \n",
      "tensor([[11, 12, 13],\n",
      "        [14, 15, 16],\n",
      "        [17, 18, 19],\n",
      "        [21, 22, 23],\n",
      "        [24, 25, 26],\n",
      "        [27, 28, 29]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([ [11,12,13],[14,15,16],[17,18,19],\n",
    "                    [21,22,23],[24,25,26],[27,28,29],],)\n",
    "display(f\"type: {type(t1)}, dtype: {t1.dtype}, shape: {t1.shape}\")\n",
    "print(f\"value: \\n{t1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reshapeしても形が変わっているだけで、並び順は変わらない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.int64, shape: torch.Size([3, 6])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: \n",
      "tensor([[11, 12, 13, 14, 15, 16],\n",
      "        [17, 18, 19, 21, 22, 23],\n",
      "        [24, 25, 26, 27, 28, 29]])\n"
     ]
    }
   ],
   "source": [
    "t1_reshape = t1.reshape(3,6)\n",
    "display(f\"type: {type(t1_reshape)}, dtype: {t1_reshape.dtype}, shape: {t1_reshape.shape}\")\n",
    "print(f\"value: \\n{t1_reshape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### transpose\n",
    "- transposeを使うと、次元を入れ替え、順番も変更できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.int64, shape: torch.Size([3, 6])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: \n",
      "tensor([[11, 14, 17, 21, 24, 27],\n",
      "        [12, 15, 18, 22, 25, 28],\n",
      "        [13, 16, 19, 23, 26, 29]])\n"
     ]
    }
   ],
   "source": [
    "t1_transpose = t1.transpose(0,1)\n",
    "display(f\"type: {type(t1_transpose)}, dtype: {t1_transpose.dtype}, shape: {t1_transpose.shape}\")\n",
    "print(f\"value: \\n{t1_transpose}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 4次元配列などでも同様のことができるが、深く考えず、添え字が入れ替わっているだけと思えばいい。\n",
    "  - 以下はバッチと画素の添え字を入れ替えている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1000, 128, 128, 3])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([3, 128, 128, 1000])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = torch.randn((1000,128,128,3), dtype=torch.float32)\n",
    "display(f\"type: {type(img1)}, dtype: {img1.dtype}, shape: {img1.shape}\")\n",
    "\n",
    "img1_transpose = img1.transpose(0,3)\n",
    "display(f\"type: {type(img1_transpose)}, dtype: {img1_transpose.dtype}, shape: {img1_transpose.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ただしtransposeは、実は実際のメモリ上の順番を入れ替えていない。\n",
    "- ほんとに物理的なメモリ配置も要素順に合わせたい場合は、以下のようにする必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([3, 128, 128, 1000])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1_transpose2 = img1.transpose(0,3).contiguous() # contiguousを付ける。\n",
    "display(f\"type: {type(img1_transpose2)}, dtype: {img1_transpose2.dtype}, shape: {img1_transpose2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- contiguousに何の意味があるか、というと。\n",
    "- そもそもreshapeと似た処理にviewというものがある。\n",
    "- このviewは、要素順と物理上のメモリ配置が異なると、動作しない。\n",
    "- なのでtranspose後にviewを実施して変形する場合は、contiguousが必要。reshapeは良い感じにしてくれるので、contiguousが不要。\n",
    "  - transpose -> contiguous -> view\n",
    "  - transpose -> reshape\n",
    "- reshapeはpytorchに後から追加されたので、viewが存在する？viewのメリットも何かあるのかもしれない。\n",
    "  - 物理上の配置が変わらないから、配列の複製が簡単とか？\n",
    "- view, reshape, transposeについては、こちらの記事も参考\n",
    "  - https://qiita.com/kenta1984/items/d68b72214ce92beebbe2"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhr7j4wWVrVpU+NTTjiYRp",
   "name": "2021-09-18_kaggle_weekly.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
