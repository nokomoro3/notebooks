{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l92fnMTyG2qf"
   },
   "source": [
    "### References\n",
    "- https://jovian.ai/aakashns/01-pytorch-basics\n",
    "- https://jovian.ai/aakashns/02-linear-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l92fnMTyG2qf"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1632324690044,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "DjzGBa5Cx5SJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lJ_y568QH9ge"
   },
   "source": [
    "### gradとは\n",
    "- 微分対象にしたい変数に、requires_grad=Trueをする。\n",
    "- これらを使用した演算結果は、backwardできるように勝手になる。\n",
    "- backwardは誤差逆伝搬のこと。\n",
    "- 機械学習のパラメータは、再急降下法により更新され、最適値を目指す。\n",
    "- loss関数を各パラメータで偏微分した値でパラメータを更新する。\n",
    "  - lossをy、parametersをX、更新後のparametersをX'とすると、更新式は以下となる。\n",
    "  - X'[t] = X[t] - a * dy / dX[t]\n",
    "  - ここで、aはいわゆるlearning_rateである。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1632325014553,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "r7LkwbB9HSiR",
    "outputId": "8f3fa3d5-8ac1-4780-bf9d-28f6dd63c144"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True) # これで微分対象となる\n",
    "b = torch.tensor(5., requires_grad=True) # これで微分対象となる\n",
    "x, w, b\n",
    "\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWKwfFWVJ0Ag"
   },
   "source": [
    "- くらえ！自動微分！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1632325017396,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "0gLhtjBPHdrd",
    "outputId": "91ca8062-3892-4c37-f307-dded1c5ee33f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dy/dx = None, dy/dw = 3.0, dy/db = 1.0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.backward()\n",
    "display(f\"dy/dx = {x.grad}, dy/dw = {w.grad}, dy/db = {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1K_SfO0LF_f"
   },
   "source": [
    "- ちなみに微分前に、微分を覗くとNoneになっている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1632325086284,
     "user": {
      "displayName": "Shogo NAKAMURA",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gjq871bPdbPzEDWuA7GEmzJIZo26eEff3bho2Ijlw=s64",
      "userId": "05714879921574505023"
     },
     "user_tz": -540
    },
    "id": "LetcerHDJ-Nu",
    "outputId": "3bae3799-a48e-495e-b8cc-9d4772ebf3a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy/dx = None, dy/dw = None, dy/db = None\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3.)\n",
    "w = torch.tensor(4., requires_grad=True) # これで微分対象となる\n",
    "b = torch.tensor(5., requires_grad=True) # これで微分対象となる\n",
    "print(f\"dy/dx = {x.grad}, dy/dw = {w.grad}, dy/db = {b.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 線形回帰\n",
    "- 何かyを推定する際に、入力情報の線形結合でモデル化する場合、これを線形モデルという。\n",
    "  - モデルとしてはこんな感じ。なんかの係数と入力ベクトルの和で表現されるなら全部線形モデル。\n",
    "    - y' = b + a0 * x0 + a1 * x1 ...\n",
    "  - よく、線形は１次関数とか言われますけど、２次関数も線形モデルです。\n",
    "  - なぜなら、以下のような２次関数も入力の線形結合だから。\n",
    "    - y' = b + a0 * x + a1 * x * x\n",
    "- せっかくなんで、pandas使ってみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>温度</th>\n",
       "      <th>降水量</th>\n",
       "      <th>湿度</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>67</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91</td>\n",
       "      <td>88</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>134</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>43</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69</td>\n",
       "      <td>96</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    温度  降水量  湿度\n",
       "0   73   67  43\n",
       "1   91   88  64\n",
       "2   87  134  58\n",
       "3  102   43  37\n",
       "4   69   96  70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame([[73, 67, 43, 56, 70], \n",
    "                   [91, 88, 64, 81, 101], \n",
    "                   [87, 134, 58, 119, 133], \n",
    "                   [102, 43, 37, 22, 37], \n",
    "                   [69, 96, 70, 103, 119]], columns=[\"温度\", \"降水量\", \"湿度\", \"apples\", \"oranges\"])\n",
    "display(df[[\"温度\", \"降水量\", \"湿度\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 入力と正解をtensorにする。\n",
    "  - pandas -> numpy -> tensorに変換する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = torch.from_numpy(df[[\"温度\", \"降水量\", \"湿度\"]].values.astype(np.float32))\n",
    "display(inputs.shape)\n",
    "\n",
    "targets = torch.from_numpy(df[[\"apples\", \"oranges\"]].values.astype(np.float32))\n",
    "display(targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- パラメータ初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4211,  0.8010,  1.7180],\n",
       "        [-1.3150,  0.9908,  2.3860]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-9.9870e-01, -1.5625e-04], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "display(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- モデル定義\n",
    "  - 初期値はランダムなので、この時点で推論しても意味不明である。\n",
    "  - .t()は転置になるらしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[303.2856,  72.9860],\n",
       "        [399.7655, 120.2286],\n",
       "        [416.6189, 156.7496],\n",
       "        [343.9658,  -3.2445],\n",
       "        [363.2171, 171.4011]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model(x):\n",
    "    return x @ w.t() + b\n",
    "\n",
    "preds = model(inputs)\n",
    "display(preds, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 誤差関数定義\n",
    "  - 学習の目標とする、最小化したい指標を定義する。\n",
    "  - .numel()は要素数になるらしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42802.1797, grad_fn=<DivBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MSE ... Mean squared error\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()\n",
    "\n",
    "loss = mse(preds, targets)\n",
    "display(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 再度、微分じゃ！くらえ！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4211,  0.8010,  1.7180],\n",
       "        [-1.3150,  0.9908,  2.3860]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[24749.5703, 24665.1602, 15684.8203],\n",
       "        [  708.9462,  1674.9237,   983.1072]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(w) # これは前と一緒\n",
    "display(w.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 微分を元に再急降下法の式で更新する。\n",
    "- この更新計算時は、微分は不要なので、no_gradというcontextmanagerが必要。\n",
    "- contextmanagerは自分で作成もできる。以下を参考。\n",
    "  - https://qiita.com/QUANON/items/c5868b6c65f8062f5876"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e-5がlearning_rateである。\n",
    "with torch.no_grad():\n",
    "    w -= w.grad * 1e-5\n",
    "    b -= b.grad * 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 更新が終わったら、次の更新に備えて、gradをゼロに戻しておいた方が良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w.grad.zero_()\n",
    "b.grad.zero_()\n",
    "display(w.grad, b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 更新後の値で、再度推論をし、誤差を計算しなおして、誤差が減ることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(29404.9785, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複数回のepochで学習\n",
    "- 複数回実行する形式で振り返ります。\n",
    "- トータルとしてこういう流れが必要です。\n",
    "- 少し見た目もおしゃれにしました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d3dc557c5d8438eaef40cad9575a9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# 入力\n",
    "inputs = torch.from_numpy(df[[\"温度\", \"降水量\", \"湿度\"]].values.astype(np.float32))\n",
    "\n",
    "# 出力(正解)\n",
    "targets = torch.from_numpy(df[[\"apples\", \"oranges\"]].values.astype(np.float32))\n",
    "\n",
    "# パラメータ初期化\n",
    "w = torch.randn(2, 3, requires_grad=True)\n",
    "b = torch.randn(2, requires_grad=True)\n",
    "\n",
    "# モデル定義\n",
    "def model(x):\n",
    "    return x @ w.t() + b\n",
    "\n",
    "# 誤差関数定義\n",
    "def mse(t1, t2):\n",
    "    diff = t1 - t2\n",
    "    return torch.sum(diff * diff) / diff.numel()\n",
    "\n",
    "# Train for 100 epochs\n",
    "with tqdm(range(100)) as pbar:\n",
    "    for i in pbar:\n",
    "        time.sleep(0.05)\n",
    "        preds = model(inputs)\n",
    "        loss = mse(preds, targets)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            w -= w.grad * 1e-5\n",
    "            b -= b.grad * 1e-5\n",
    "            w.grad.zero_()\n",
    "            b.grad.zero_()\n",
    "        \n",
    "        pbar.set_description(f\"[loss: {loss:.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- predsとtargetsの値を比較してみます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 59.6970,  75.3024],\n",
       "        [ 87.3153,  87.3418],\n",
       "        [103.0003, 155.2428],\n",
       "        [ 37.4912,  64.6332],\n",
       "        [100.9570,  79.7776]], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  70.],\n",
       "        [ 81., 101.],\n",
       "        [119., 133.],\n",
       "        [ 22.,  37.],\n",
       "        [103., 119.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(preds, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Creating a new project \"nokomoro3/pytorch-tutorial-02-linear-model\"\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/nokomoro3/pytorch-tutorial-02-linear-model\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/nokomoro3/pytorch-tutorial-02-linear-model'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jovian\n",
    "jovian.commit(project='pytorch-tutorial-02-linear-model', filename='02_linear_model.ipynb')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPhr7j4wWVrVpU+NTTjiYRp",
   "name": "2021-09-18_kaggle_weekly.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
