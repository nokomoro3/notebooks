{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "344284c7-9c2f-48de-8053-d95f3e0e9b22",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "- 前回までは、ロジスティック回帰なので、まだDeep Learningではなかった。\n",
    "- ここからは、隠れ層や活性化関数を使うことで、Deep Learningになる。\n",
    "- テーマはmnistをつかう。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b7da5-9188-45d7-a466-b5cb69ff2724",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22ded57f-5f0c-463e-b936-e79e354a79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7801be6-1a08-4709-bbaf-123f4202e592",
   "metadata": {},
   "source": [
    "### IO\n",
    "\n",
    "- 入出力ファイルの場所は先頭に記述する方が、後からわかりやすい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371df267-19ca-4c17-aaa1-316253a5e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DOWNLOAD_PATH = pathlib.Path('./data').joinpath('03_mnist', 'input')\n",
    "\n",
    "# pathlib.Path('./data').joinpath('03_mnist', 'output').mkdir(parents=True, exist_ok=True)\n",
    "# OUTPUT_MODEL_FILE = pathlib.Path('./data').joinpath('03_mnist', 'output', 'mnist-logistic.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b5ee6-05f1-4a13-923d-4c4ab1b8a531",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f4a1fa6-e8c1-435f-9073-238283aeae6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"type: <class 'torch.Tensor'>, dtype: torch.float32, shape: torch.Size([1, 28, 28])\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"type: <class 'int'>\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = MNIST(root=INPUT_DOWNLOAD_PATH, \n",
    "                train=True,\n",
    "                transform=transforms.ToTensor())\n",
    "\n",
    "test_ds = MNIST(root=INPUT_DOWNLOAD_PATH, \n",
    "                train=False,\n",
    "                transform=transforms.ToTensor())\n",
    "\n",
    "train_ds, val_ds = random_split(train_ds, [50000, 10000])\n",
    "image, label = train_ds[0]\n",
    "\n",
    "display(f\"type: {type(image)}, dtype: {image.dtype}, shape: {image.shape}\")\n",
    "display(f\"type: {type(label)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d0646d-b4f0-4d99-913c-a31b810f4bd2",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21933fb-3e0d-4aed-8d9a-d576d614252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b8572-9740-4743-8342-94d622e126d2",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce1e6725-688a-4fb2-b942-33fb69257c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, BATCH_SIZE)\n",
    "test_loader = DataLoader(test_ds, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac96e6-8d49-4578-b9bd-cc43ed146a33",
   "metadata": {},
   "source": [
    "### Model\n",
    "- 説明が面倒なので、モデル定義からやっちゃいます。\n",
    "- linearが2個になっただけなんです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3f7e71b-7111-48dc-a1cf-2a23959fd618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_shape, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        input_size = 1\n",
    "        for i in input_shape:\n",
    "            input_size = input_size * i\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, self.input_size)\n",
    "        \n",
    "        out = self.linear1(xb)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        return out\n",
    "\n",
    "model = CustomModel(image.shape, 32, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b35fea-3fe7-4a92-9b84-a4f39e628a67",
   "metadata": {},
   "source": [
    "- parameterのダンプは、state_dictを使った方が、名前もわかっていい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d57f5bcd-b74d-432c-a7c4-53811120c3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dtype: torch.float32, shape: torch.Size([32, 784])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dtype: torch.float32, shape: torch.Size([32])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear2.weight\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dtype: torch.float32, shape: torch.Size([10, 32])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear2.bias\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dtype: torch.float32, shape: torch.Size([10])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in model.state_dict().items():\n",
    "    print(k)\n",
    "    display(f\"dtype: {v.dtype}, shape: {v.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f30837-2e67-4464-beb0-58cd5ad91eda",
   "metadata": {},
   "source": [
    "- 一応推論テスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21673c3f-7ac6-4025-9fc4-feb476af8f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dtype: torch.float32, shape: torch.Size([128, 10])'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3086531162261963\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    display(f\"dtype: {outputs.dtype}, shape: {outputs.shape}\")\n",
    "    \n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    print('Loss:', loss.item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8c7d94-c4b3-4cb1-aee8-15893f717481",
   "metadata": {},
   "source": [
    "### GPU使用\n",
    "- GPUはなんかすごい並列処理できるコア\n",
    "- CPUよりは、1コア当たりは貧弱。\n",
    "- 元々画像処理向けなので、画像は画素毎に同じ処理をするので並列処理が得意。\n",
    "- これを画像以外の用途につかうのが、GP(General Purpose)GPU。\n",
    "- PyTorhcなどのライブラリはGPGPUが手軽にできるのも利点。\n",
    "<br>\n",
    "<br>\n",
    "- デバイス数や使用可能かどうかを確かめる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c84dcb18-6a1d-4b07-8fe3-6519b3002d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU available: False, GPU Num: 0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(f\"GPU available: {torch.cuda.is_available()}, GPU Num: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    display(f\"cuda:{i}, name:{torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291a394-99ef-4d1e-958c-4e90955b3134",
   "metadata": {},
   "source": [
    "- マシンに応じた設定になるような関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f33af5b2-7f99-434f-be57-52266317244b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f673c857-9b6f-465b-94ae-1b1ab823618f",
   "metadata": {},
   "source": [
    "- 再帰呼び出しで、データを転送する関数。\n",
    "- 転送自体は、tensorのtoメソッドでできるみたい。\n",
    "- ちなみに、non_blockingは高速化の仕組みのようなもの。詳細はここら辺参照。\n",
    "  - https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2862dc51-74c2-404a-8cc3-d3acb2add836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d524eef-3bdd-48d4-84f1-eca766a4056a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.4474,  1.9290,  0.4737],\n",
       "          [-1.5279, -0.9231,  0.4110],\n",
       "          [-2.0824,  0.3134,  2.5996]],\n",
       " \n",
       "         [[-0.6124,  0.4139,  1.0309],\n",
       "          [-1.0299, -0.0945, -1.3544],\n",
       "          [ 1.2997, -0.3557,  1.3776]],\n",
       " \n",
       "         [[-1.6942,  0.1673,  2.2078],\n",
       "          [-2.0198,  1.1477,  0.0209],\n",
       "          [-0.5538, -0.4968,  0.6305]]]),\n",
       " tensor([[[ 0.4474,  1.9290,  0.4737],\n",
       "          [-1.5279, -0.9231,  0.4110],\n",
       "          [-2.0824,  0.3134,  2.5996]],\n",
       " \n",
       "         [[-0.6124,  0.4139,  1.0309],\n",
       "          [-1.0299, -0.0945, -1.3544],\n",
       "          [ 1.2997, -0.3557,  1.3776]],\n",
       " \n",
       "         [[-1.6942,  0.1673,  2.2078],\n",
       "          [-2.0198,  1.1477,  0.0209],\n",
       "          [-0.5538, -0.4968,  0.6305]]])]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn(3,3,3)\n",
    "to_device([t, t], device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "app"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
